{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import pandas as pd\n",
    "import umap # First time you run this enter pip install umap-learn in your Anaconda Prompt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 'E-GEOD-100911.aggregated_filtered_normalised_counts.mtx'\n",
    "c = 'E-GEOD-100911.aggregated_filtered_normalised_counts.mtx_cols'\n",
    "r = 'E-GEOD-100911.aggregated_filtered_normalised_counts.mtx_rows'\n",
    "cols = []\n",
    "rows = []\n",
    "data = io.mmread(norm)\n",
    "with open(c) as file:\n",
    "    for line in file:\n",
    "        cols.append(line.rstrip())\n",
    "\n",
    "# with open(r) as file:\n",
    "#     for line in file:\n",
    "#         rows.append(line.rstrip().split('\\t')[0])\n",
    "# arr = data.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# norm_counts = pd.DataFrame(arr, index = rows, columns = cols)\n",
    "# norm_counts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was run to convert the gene transcript IDs to KEGG IDs, since this process took so long\n",
    "# the result was saved to a csv (geneID.csv) file and this code is not needed anymore. \n",
    "\n",
    "# from Bio import Entrez\n",
    "# import time\n",
    "# import csv\n",
    "\n",
    "# Entrez.email = \"mdpouls1@gmail.com\"\n",
    "# geneIDs = []\n",
    "# rowsTest = rows[15000:]\n",
    "# i = 0\n",
    "# while i < len(rowsTest):\n",
    "#     for t in range(3):\n",
    "#         if i < len(rowsTest):\n",
    "#             handle = Entrez.esearch(db=\"gene\", term=rowsTest[i])\n",
    "#             record = Entrez.read(handle)\n",
    "#             if len(record['IdList']) == 1:\n",
    "#                 geneIDs.append(record['IdList'][0])\n",
    "#             elif len(record['IdList']) > 1:\n",
    "#                 geneIDs.append('multiple')\n",
    "#             else:\n",
    "#                 geneIDs.append('NaN')\n",
    "#             handle.close()\n",
    "#             i += 1\n",
    "#     time.sleep(1)\n",
    "\n",
    "# with open('geneID.csv', 'a') as f:\n",
    "#     for gene in geneIDs:\n",
    "#         f.write('{},'.format(gene))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_Data = pd.read_csv('geneID.csv')\n",
    "IDs = ID_Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_counts['geneIDs'] = IDs\n",
    "# norm_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataFile.txt', 'w') as file:\n",
    "#     file.write(' '.join(norm_counts['geneIDs'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotationData = pd.read_table('uniprotData.tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotationData = annotationData.rename(columns={\"yourlist:M20210331A94466D2655679D1FD8953E075198DA81B3BDFU\": \"Ids\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotationData = annotationData.drop(\"yourlist:M20210331A94466D2655679D1FD8953E075198DA81B3B2BO\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotationData.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "norm_counts = pd.read_csv('norm_counts_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_counts = norm_counts.set_index('Unnamed: 0')\n",
    "norm_transpose = norm_counts.transpose()\n",
    "norm_transpose.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_transpose_dropped = norm_transpose.drop('geneIDs')\n",
    "norm_transpose_dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geneID_dict['64604']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #comvert the gene ontology codes to dummy columns in a dataframe for each gene ID then saved as a csv. \n",
    "\n",
    "# GO = []\n",
    "# go_dict = {}\n",
    "# for line in annotationData['Gene ontology (biological process)'].str.split(';'):\n",
    "#     if type(line) == list:\n",
    "#         for item in line:\n",
    "#             GO.append(item.strip())\n",
    "\n",
    "# for term in GO:\n",
    "#     if term not in go_dict:\n",
    "#         go_dict[term] = []\n",
    "\n",
    "# for line in annotationData['Gene ontology (biological process)'].str.split(';'):\n",
    "#     item_dict = {}\n",
    "#     if type(line) == list:\n",
    "#         for item in line:\n",
    "#             item_dict[item.strip()] = True\n",
    "#         for k,v in go_dict.items():\n",
    "#             if k in item_dict:\n",
    "#                 v.append(1)\n",
    "#             else:\n",
    "#                 v.append(0)\n",
    "\n",
    "        \n",
    "# go_df = pd.DataFrame.from_dict(go_dict)\n",
    "# go_df['geneId'] = annotationData['Ids']\n",
    "\n",
    "# go_df = go_df.set_index('geneId')\n",
    "# go_df.head()\n",
    "\n",
    "# go_df.to_csv('goData.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in go_dict.items():\n",
    "#     print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_counts_id = norm_counts.set_index(\"geneIDs\")\n",
    "# new = norm_counts.merge(go_df,left_on='geneIDs', right_on='geneId')\n",
    "# new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new = new.set_index('geneIDs')\n",
    "# new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srr_dict = norm_counts_id.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srr_dict['SRR5810686']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_dict = go_df.to_dict('split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geneID_dict = {}\n",
    "# for ind, data in gene_dict.items():\n",
    "#     geneID_dict[ind] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srr_dict = norm_counts_id.to_dict()\n",
    "# gene_dict = go_df.to_dict('split')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geneID_dict = {}\n",
    "# for ind, data in gene_dict.items():\n",
    "#     geneID_dict[ind] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = gene_dict['index']\n",
    "# data = gene_dict['data']\n",
    "\n",
    "# geneID_dict = {}\n",
    "# for i in range(len(ids)):\n",
    "#     geneID_dict[ids[i]] = data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srr_genes_dict_values = {}\n",
    "# for srr,genes in srr_dict.items():\n",
    "#     genes_GO = np.zeros((5075,), dtype=int)\n",
    "#     for gene,value in genes.items():\n",
    "#         if value > 0:\n",
    "#             if gene in geneID_dict:\n",
    "#                 genes_GO = np.add(genes_GO,np.multiply(value, np.array(geneID_dict[gene])))\n",
    "#     srr_genes_dict_values[srr] = genes_GO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = go_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gene_annotation_values_df = pd.DataFrame.from_dict(srr_genes_dict_values, orient='index', columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene_annotation_values_df.head()norm_counts['geneIDs'] = IDs\n",
    "# norm_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_counts.to_csv('norm_counts_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('dataFile.txt', 'w') as file:\n",
    "#     file.write(' '.join(norm_counts['geneIDs'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotationData = pd.read_table('uniprotData.tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gene_annotation_values_df.to_csv('GeneAnnotation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotationData = annotationData.drop(\"yourlist:M20210331A94466D2655679D1FD8953E075198DA81B3B2BO\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#annotationData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP Reduction:\n",
    "\n",
    "See the UMAP Documentation page for details. The module import cell at the top of this notebook has instructions for downloading the scikit learn plug-in for UMAP.\n",
    "\n",
    "NOTE This is a first pass - I'm not super sure it is ready to go. Next steps\n",
    "\n",
    "1 We need to cluster the data and assign tags to the data points\n",
    "\n",
    "2 Add a third dimension to the UMAP reduction\n",
    "\n",
    "3 Plot data in altair to allow interaction\n",
    "\n",
    "4 Add interaction steps, tags, whatever else we're doing!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_counts_temp = norm_counts\n",
    "norm_counts_temp = norm_counts_temp.drop(['geneIDs'],axis=1).transpose()\n",
    "norm_vals = norm_counts_temp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vals_scaled = StandardScaler().fit_transform(norm_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMAP_reducer = umap.UMAP()\n",
    "reduced_genes = UMAP_reducer.fit_transform(norm_vals_scaled)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(reduced_genes[:,0],reduced_genes[:,1])\n",
    "plt.gca().set_aspect('equal','datalim')\n",
    "plt.title('UMAP projection of Zebra Fish genes, unclustered')\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = norm_vals_scaled\n",
    "# PCA\n",
    "pca_mod = PCA(n_components = 7)\n",
    "data_pca = pca_mod.fit_transform(X)\n",
    "PCs =pca_mod.components_\n",
    "PCs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMAP_mod = umap.UMAP(n_neighbors = 7, min_dist = 0.2, n_components = 3).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K means\n",
    "y_pred = KMeans(n_clusters=7, max_iter=5).fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors\n",
    "from matplotlib.colors import ListedColormap\n",
    "colors = ListedColormap(sns.color_palette('bright', 7).as_hex())\n",
    "# plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(UMAP_mod[:, 0], UMAP_mod[:, 1],zs= UMAP_mod[:, 2], c=y_pred, cmap= colors, s=20)\n",
    "ax.set_xlabel('Dimension 1')\n",
    "ax.set_ylabel('Dimension 2')\n",
    "ax.set_zlabel('Dimension 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(UMAP_mod[:,0],UMAP_mod[:,1], c = y_pred, cmap = colors, s=15)\n",
    "plt.gca().set_aspect('equal','datalim')\n",
    "plt.title('UMAP projection of Zebra Fish genes, unclustered')\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get top gene ontologies:  \n",
    "**The** top gene ontologies are defined in this project as those that have the largest (absolute) parameter value in the final equation for the principal direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = pd.read_csv('GeneAnnotation.csv')\n",
    "annot_vals = annotation.values\n",
    "\n",
    "annot_scaled = StandardScaler().fit_transform(annot_vals)\n",
    "\n",
    "\n",
    "# PCA on gene ontologies: Use this to figure out het\n",
    "pca_mod = PCA(n_components = 1) \n",
    "data_pca = pca_mod.fit_transform(annot_scaled)\n",
    "PCs =pca_mod.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCs_df = pd.DataFrame(PCs)\n",
    "PCs_df = PCs_df.transpose()\n",
    "PCs_df[1] = abs(PCs_df[0])\n",
    "topGo = PCs_df[1].sort_values(ascending = False).head(100).index #List of the index of the top gene ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_annotations = annotation.iloc[:,topGo] # Grab the top 100 annotations\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "top_annotations[:] = min_max_scaler.fit_transform(top_annotations.values) #Scale the data to be in range [0,1]\n",
    "top_annotations.columns = np.arange(0,len(top_annotations.columns))\n",
    "top_annotations.head() #df with only the top 100 most important group ontologies listed for each cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization:\n",
    "**Overview**\n",
    " - The 'base' plot is the 2-D UMAP plot plotted using Altair. \n",
    " - A user can then select a region-of-interest to create the breakout histogram plots of predominate gene ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create visualization dataframe:  \n",
    "**Overview** by creating a dataframe with the reduced dimension data and add in additional properties as necessary (i.e. cluster number, ontology, etc.)  \n",
    "  \n",
    "**To-do:**  \n",
    " - Add cluster IDs\n",
    " - Add gene ontologies\n",
    " - Add primary genes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'base' dataframe:\n",
    "column_names = [\"UMAP x\",\"UMAP y\"]\n",
    "vis_data = pd.DataFrame(reduced_genes, columns = column_names)\n",
    "vis_data[\"Clusters\"] = y_pred # Add clusters:\n",
    "vis_data['IDs'] = top_annotations.index.values\n",
    "# vis_data[top_annotations.columns] = top_annotations.values # Bring in the 'top annotations'\n",
    "\n",
    "# vis_data.head()\n",
    "# vis_data.plot.bar(y=1)\n",
    "vis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ceate a 'long' chart of the form [CellID | Annotation type | Annotation Value] (and probably UMAPs...)\n",
    "annotation_play = top_annotations\n",
    "annotation_play['ids'] = annotation_play.index\n",
    "vals = np.arange(0,20)\n",
    "annotation_play = pd.melt(top_annotations, id_vars=['ids'], value_vars=vals)\n",
    "annotation_play['UMAP x'] = ''\n",
    "annotation_play['UMAP y'] = ''\n",
    "annotation_play['Cluster'] = ''\n",
    "\n",
    "## ADD THE UMAP LOCATIONS AND CLUSTER ID FOR EACH INSTANCE OF EACH CELL:\n",
    "# PS: Kinda hacked this one together.... so it takes a quick sec to run\n",
    "cnt = 1\n",
    "for i in range(len(annotation_play)):\n",
    "    for j in range(len(vis_data)):\n",
    "        if annotation_play.loc[i, 'ids'] == vis_data.loc[j,'IDs']:\n",
    "            annotation_play.loc[i, 'UMAP x'] = float(vis_data.loc[j,'UMAP x'])\n",
    "            annotation_play.loc[i, 'UMAP y'] = float(vis_data.loc[j,'UMAP y'])\n",
    "            annotation_play.loc[i, 'Cluster'] = int(vis_data.loc[j,'Clusters'])\n",
    "            print(len(annotation_play) - cnt)\n",
    "            cnt += 1\n",
    "\n",
    "annotation_play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 'master' plot  \n",
    "**TODO** \n",
    " - Add cluster colors\n",
    " - Add IDs when hovering?\n",
    " - Add ROI selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create histogram plot of ontologies:\n",
    "**Thoughts:**\n",
    " - Altair does seem to be one of the easier plotting systems to select data\n",
    " - Altair does not output the indicies of the ROI without an API that may be out there...\n",
    " - I can 'transform' the data using:\n",
    "  - Density Transform | create a vector of all of the ontologies, show a density plot of these ontologies\n",
    "  - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display tool!\n",
    "**This is where our interaction is!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = alt.selection_interval()\n",
    "\n",
    "scatter_base = alt.Chart(annotation_play).mark_point().encode(\n",
    "    x='UMAP x',\n",
    "    y='UMAP y',\n",
    "    color = 'Cluster'\n",
    ").properties(\n",
    "    width = 500,\n",
    "    height = 200\n",
    ").add_selection(ROI)\n",
    "\n",
    "hist_base = alt.Chart(annotation_play).mark_bar().encode(\n",
    "    x='variable',\n",
    "    y='mean(value):Q'\n",
    ").properties(\n",
    "    width = 500,\n",
    "    height = 200\n",
    ").transform_filter(\n",
    "    ROI\n",
    ")\n",
    "\n",
    "scatter_base & hist_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This is unpublished data from the Gagnon lab from the [cell ranger](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/what-is-cell-ranger) pipeline. I loaded the files, cleaned the data and created a (large) csv file to load in.  As discussed in peer feedback, the unpublished data will be shared will a Google Drive link below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testis1_data_ = io.mmread('matrix.mtx.gz')\n",
    "#data_arr = testis1_data_.toarray()\n",
    "#data_col = pd.read_csv('barcodes.tsv.gz', compression = 'gzip', header=None, sep = '\\t')\n",
    "#data_row = pd.read_csv('features.tsv.gz', compression = 'gzip', header=None,sep = '\\t')\n",
    "#data_rows = data_row[1]\n",
    "#data_cols = []\n",
    "#for b in data_col[0]:\n",
    "#    data_cols.append(b)\n",
    "#data_counts = pd.DataFrame(data_arr, index = data_rows, columns = data_cols)\n",
    "#data_counts.to_csv('data_counts_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the link to the csv file I generated with the code above: [t1_counts_data.csv](https://drive.google.com/file/d/1aIR4w9TIOnMxziE5aQVjIMAWvqEY6Mvq/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The csv file above needs to be downloaded to load this cell\n",
    "# It is a large dataset, so it may take a while to load\n",
    "data_counts = pd.read_csv('t1_counts_data.csv', header = 0)\n",
    "data_counts.set_index('1', inplace = True)\n",
    "data_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality control of the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# percentage of mitochondrial rna\n",
    "mitochondrial = data_counts[data_counts.index.str.contains('mt-') > 0].sum(0)\n",
    "total = data_counts.sum(0)\n",
    "mito_percentage = (mitochondrial/total) * 100\n",
    "filter_out = mito_percentage[mito_percentage < 5].index\n",
    "data_counts = data_counts[filter_out] # filter out anything higher than 5%\n",
    "\n",
    "# filter by counts of genes (a very large amount of transcribed genes implies more than one cell is captured)\n",
    "gene_counts = []\n",
    "for i,cell in enumerate(data_counts.columns):\n",
    "    counter = 0\n",
    "    for row in data_counts.iloc[:,i]:\n",
    "        if row > 0:\n",
    "            counter += 1\n",
    "    gene_counts.append(counter)\n",
    "count_mask = []\n",
    "for count in gene_counts:\n",
    "    if count > 200 & count < 2500:\n",
    "        count_mask.append(gene_counts.index(count))\n",
    "data_counts = data_counts.iloc[:,count_mask]\n",
    "data_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define features (genes) and samples (cell_ids)\n",
    "genes = data_counts.index.values\n",
    "cell_ids = data_counts.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
